"""
Script d'entra√Ænement d'un classificateur bas√© sur les landmarks MediaPipe
Beaucoup plus rapide et pr√©cis que le CNN sur images
"""

import numpy as np
import pickle
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# Configuration
LANDMARKS_PATH = 'model/landmarks_dataset.pkl'
MODEL_PATH = 'model/landmark_classifier.pkl'
SCALER_PATH = 'model/landmark_scaler.pkl'

def load_data():
    """
    Charge les donn√©es de landmarks
    """
    print("üìÇ Chargement des donn√©es...")
    with open(LANDMARKS_PATH, 'rb') as f:
        data = pickle.load(f)
    
    X = data['landmarks']
    y = data['labels']
    class_names = data['class_names']
    
    print(f"‚úÖ {len(X)} √©chantillons charg√©s")
    print(f"‚úÖ {len(class_names)} classes")
    print(f"‚úÖ Shape: {X.shape}")
    
    return X, y, class_names

def train_random_forest(X_train, y_train, X_test, y_test, class_names):
    """
    Entra√Æne un Random Forest (rapide et efficace)
    """
    print("\n" + "=" * 60)
    print("   üå≤ RANDOM FOREST CLASSIFIER")
    print("=" * 60 + "\n")
    
    print("üîÑ Entra√Ænement en cours...")
    
    clf = RandomForestClassifier(
        n_estimators=200,
        max_depth=30,
        min_samples_split=2,
        min_samples_leaf=1,
        random_state=42,
        n_jobs=-1,
        verbose=0
    )
    
    clf.fit(X_train, y_train)
    
    # √âvaluation
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"‚úÖ Pr√©cision: {accuracy*100:.2f}%")
    
    return clf, accuracy

def train_mlp(X_train, y_train, X_test, y_test, class_names):
    """
    Entra√Æne un r√©seau de neurones MLP (plus pr√©cis)
    """
    print("\n" + "=" * 60)
    print("   üß† R√âSEAU DE NEURONES (MLP)")
    print("=" * 60 + "\n")
    
    # Normalisation des donn√©es
    print("üîÑ Normalisation...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print("üîÑ Entra√Ænement en cours...")
    
    clf = MLPClassifier(
        hidden_layer_sizes=(128, 64, 32),
        activation='relu',
        solver='adam',
        alpha=0.0001,
        batch_size=32,
        learning_rate='adaptive',
        learning_rate_init=0.001,
        max_iter=500,
        random_state=42,
        verbose=False,
        early_stopping=True,
        validation_fraction=0.1,
        n_iter_no_change=20
    )
    
    clf.fit(X_train_scaled, y_train)
    
    # √âvaluation
    y_pred = clf.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"‚úÖ Pr√©cision: {accuracy*100:.2f}%")
    
    return clf, scaler, accuracy

def plot_confusion_matrix(y_test, y_pred, class_names):
    """
    Affiche la matrice de confusion
    """
    cm = confusion_matrix(y_test, y_pred)
    
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Matrice de Confusion')
    plt.ylabel('Vraie classe')
    plt.xlabel('Classe pr√©dite')
    plt.tight_layout()
    plt.savefig('model/confusion_matrix.png', dpi=150)
    print("üìä Matrice de confusion sauvegard√©e: model/confusion_matrix.png")

def print_classification_report(y_test, y_pred, class_names):
    """
    Affiche le rapport de classification d√©taill√©
    """
    print("\n" + "=" * 60)
    print("   üìä RAPPORT DE CLASSIFICATION")
    print("=" * 60 + "\n")
    
    report = classification_report(y_test, y_pred, 
                                   target_names=class_names,
                                   zero_division=0)
    print(report)

def main():
    """
    Fonction principale
    """
    print("\n" + "üéØ " * 30)
    print("\n   ENTRA√éNEMENT DU CLASSIFICATEUR LANDMARKS\n")
    print("üéØ " * 30 + "\n")
    
    try:
        # Charger les donn√©es
        X, y, class_names = load_data()
        
        # Split train/test
        print("\nüîÄ S√©paration train/test (80/20)...")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"‚úÖ Train: {len(X_train)} √©chantillons")
        print(f"‚úÖ Test: {len(X_test)} √©chantillons")
        
        # Entra√Æner Random Forest
        rf_clf, rf_acc = train_random_forest(X_train, y_train, X_test, y_test, class_names)
        
        # Entra√Æner MLP
        mlp_clf, scaler, mlp_acc = train_mlp(X_train, y_train, X_test, y_test, class_names)
        
        # Choisir le meilleur
        print("\n" + "=" * 60)
        print("   üèÜ COMPARAISON DES MOD√àLES")
        print("=" * 60 + "\n")
        
        print(f"Random Forest: {rf_acc*100:.2f}%")
        print(f"MLP (Neural Net): {mlp_acc*100:.2f}%")
        
        if mlp_acc >= rf_acc:
            print("\n‚úÖ MLP s√©lectionn√© (meilleure pr√©cision)")
            best_clf = mlp_clf
            best_name = "MLP"
            use_scaler = True
            
            # Normaliser aussi les donn√©es de test pour les graphiques
            X_test_final = scaler.transform(X_test)
        else:
            print("\n‚úÖ Random Forest s√©lectionn√© (meilleure pr√©cision)")
            best_clf = rf_clf
            best_name = "RandomForest"
            use_scaler = False
            X_test_final = X_test
            scaler = None
        
        # Pr√©dictions finales
        y_pred = best_clf.predict(X_test_final)
        
        # Rapport de classification
        print_classification_report(y_test, y_pred, class_names)
        
        # Matrice de confusion
        plot_confusion_matrix(y_test, y_pred, class_names)
        
        # Sauvegarder le mod√®le
        model_data = {
            'classifier': best_clf,
            'scaler': scaler,
            'class_names': class_names,
            'model_type': best_name,
            'use_scaler': use_scaler
        }
        
        joblib.dump(model_data, MODEL_PATH)
        print(f"\n‚úÖ Mod√®le sauvegard√©: {MODEL_PATH}")
        
        # R√©sum√© final
        print("\n" + "=" * 60)
        print("   üéâ ENTRA√éNEMENT TERMIN√â")
        print("=" * 60)
        print(f"\nüìä Mod√®le: {best_name}")
        print(f"üìä Pr√©cision: {max(rf_acc, mlp_acc)*100:.2f}%")
        print(f"üìä Classes: {len(class_names)}")
        
        print("\nüí° √âtape suivante:")
        print("   py -3.11 live_detection_landmarks.py")
        
    except FileNotFoundError:
        print("‚ùå Fichier landmarks_dataset.pkl non trouv√©!")
        print("üí° Lancez d'abord: py -3.11 collect_landmarks.py")
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()